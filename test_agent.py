from langchain.tools import tool
import google.generativeai as genai
from geopy.geocoders import Nominatim
import time
import pandas as pd
import osmnx as ox
from models.trip_price_class import TripPricePredictor
import heapq
from tools import *
from dotenv import load_dotenv
from pathlib import Path
import os
import pickle
import re
import json

# Load environment variables
load_dotenv()

# Cache the graph to avoid reprocessing each run
CACHE_GRAPH_PATH = "graph_cache.pkl"
if os.path.exists(CACHE_GRAPH_PATH):
    with open(CACHE_GRAPH_PATH, "rb") as f:
        g = pickle.load(f)
else:
    g = ox.graph_from_xml("labeled.osm", bidirectional=True, simplify=True)
    g = attach_trips_to_graph(g)
    with open(CACHE_GRAPH_PATH, "wb") as f:
        pickle.dump(g, f)
set_graph(g)

print("âœ… Graph initialized")
print(g.nodes[list(g.nodes)[0]].keys())


# Cache pathways graph mapping
CACHE_PATHWAYS_PATH = "pathways_cache.pkl"
if os.path.exists(CACHE_PATHWAYS_PATH):
    with open(CACHE_PATHWAYS_PATH, "rb") as f:
        trip_graph, pathways_dict = pickle.load(f)
else:
    pathways = pd.read_csv('trip_pathways.csv')
    trip_graph = defaultdict(dict)
    pathways_dict = pathways.to_dict('index')
    for idx, row in pathways.iterrows():
        trip_graph[row['start_trip_id']][row['end_trip_id']] = idx 
    with open(CACHE_PATHWAYS_PATH, "wb") as f:
        pickle.dump((trip_graph, pathways_dict), f)
set_trip_graph(trip_graph, pathways_dict)




system_prompt = """
You are a smart assistant specialized in Alexandria public transportation. 
You have access to the following tools:

1. geocode_address(address) -> returns the latitude and longitude of the address.
2. get_nearest_node(lat, lon) -> returns the nearest OSM node ID.
3. explore_trips(source_node) -> returns all trips starting from this node, including walking distance.
4. find_journeys(start_trips, goal_trips) -> returns all possible journeys with path and costs (money, walking distance).
5. filter_best_journeys(journeys, max_results=5) -> returns the best journeys based on shortest walking distance and lowest cost.
6. format_journeys_for_user(journeys) -> returns a user-friendly Arabic description of the journeys.

You must always follow this workflow:
1. Find the coordinates of the start and destination using geocode_address. IMPORTANT: Always append ", Alexandria, Egypt" to the address provided by the user to ensure accuracy (e.g., if user says "Asafra", search for "Asafra, Alexandria, Egypt").
2. Convert each location into the nearest OSM node using get_nearest_node.
3. Explore trips from both start and destination nodes using explore_trips.
4. Find all possible journeys using find_journeys.
5. Filter the top journeys using filter_best_journeys.
6. Format the filtered journeys for the user using format_journeys_for_user.
7. Return only the final formatted journey description to the user. Do not return any intermediate data.

Output style requirements:
- Be clear, friendly, and concise in Arabic.
- Use headings, bullets, and icons (ğŸ›£ ğŸ’° ğŸš¶â€â™‚ï¸) similar to the tools output.
- Start with a brief confirmation of origin and destination, then list top journeys.
- For each journey: show the path (trip names), total price, and total walking distance.
- Avoid raw JSON; return a human-friendly formatted text only.
"""


def _regex_extract(query: str) -> tuple[str, str] | tuple[None, None]:
    # Disabled: fallback extraction via regex is no longer used.
    return None, None


def run_once(query: str) -> str:
    # 1) LLM parses the user query to origin/destination once (JSON-only)
    api_key = os.environ.get("GOOGLE_API_KEY", "")
    genai.configure(api_key=api_key)
    parse_prompt = (
        "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù†ÙˆØ§ÙŠØ§. Ø£Ø®Ø±Ø¬ Ù…ÙƒØ§Ù† Ø§Ù„Ø§Ù†Ø·Ù„Ø§Ù‚ ÙˆØ§Ù„ÙˆØµÙˆÙ„ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ£Ø¹Ø¯ JSON ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ ÙƒÙ„Ø§Ù… Ø¥Ø¶Ø§ÙÙŠØŒ"
        " Ø§Ø³ØªØ¹Ù…Ù„ Ø§Ù„Ù…ÙØªØ§Ø­ÙŠÙ† Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ØªÙ…Ø§Ù…Ù‹Ø§: origin Ùˆ destination. Ø£Ø¹ÙØ¯Ù‘ JSON Ù…Ø¶ØºÙˆØ· Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ø¨Ø¯ÙˆÙ† Ø£Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯Ø© ÙˆÙ„Ø§ ØªØ¹Ù„ÙŠÙ‚Ø§Øª"
        " ÙˆØ¨Ø¯ÙˆÙ† Ø£Ù‚ÙˆØ§Ø³ Ø£Ùˆ ØªÙ†Ø³ÙŠÙ‚ Ø¥Ø¶Ø§ÙÙŠ Ù…Ø«Ù„ ``` Ø£Ùˆ ```json. Ù…Ø«Ø§Ù„ Ø¯Ù‚ÙŠÙ‚: {\"origin\":\"Ø§Ù„Ù…ÙˆÙ‚Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯\",\"destination\":\"Ø§Ù„Ø¹ØµØ§ÙØ±Ø©\"}.\n\n"
        f"Ø§Ù„Ù†Øµ: {query}"
    )
    origin = None
    dest = None
    try:
        # Use a modern fast model for parsing
        parse_resp = genai.GenerativeModel("gemini-2.5-flash").generate_content(parse_prompt, request_options={"retry": None, "timeout": 20})
        raw = getattr(parse_resp, "text", "") or ""
        # Strip common code fences/backticks and language tags
        raw = re.sub(r"^```[a-zA-Z]*\n|\n```$", "", raw.strip())
        raw = raw.strip()
        # Extract first JSON object from text
        jmatch = re.search(r"\{[\s\S]*\}", raw)
        if jmatch:
            data = json.loads(jmatch.group(0))
            origin = (data.get("origin") or data.get("Ø§Ù„Ø§Ù†Ø·Ù„Ø§Ù‚") or "").strip() or None
            dest = (data.get("destination") or data.get("Ø§Ù„ÙˆØµÙˆÙ„") or "").strip() or None
    except Exception:
        pass

    # Require valid LLM parse; no regex fallback
    if not origin or not dest:
        return "ØªØ¹Ø°Ù‘Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ø§Ù†Ø·Ù„Ø§Ù‚ ÙˆØ§Ù„ÙˆØµÙˆÙ„ Ø¹Ø¨Ø± Gemini. ØªØ£ÙƒÙ‘Ø¯ Ù…Ù† ÙƒØªØ§Ø¨Ø© Ø§Ù„ØµÙŠØºØ© Ø¨ÙˆØ¶ÙˆØ­ (Ù…Ø«Ø§Ù„: Ù…Ù† [Ø§Ù„Ù…ÙƒØ§Ù† A] Ø¥Ù„Ù‰ [Ø§Ù„Ù…ÙƒØ§Ù† B]) ÙˆØ¨ÙˆØ¬ÙˆØ¯ Ù…ÙØªØ§Ø­ API ØµØ§Ù„Ø­."

    # 2) Tools pipeline (deterministic)
    src_geo = geocode_address(origin)
    dst_geo = geocode_address(dest)
    if "error" in src_geo or "error" in dst_geo:
        return "Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¨Ø¯Ù‚Ø©. Ø¬Ø±Ù‘Ø¨ ØµÙŠØºØ© Ø£Ø®Ø±Ù‰." 
    src_node = get_nearest_node(src_geo["lat"], src_geo["lon"]) 
    dst_node = get_nearest_node(dst_geo["lat"], dst_geo["lon"]) 

    # Optional debug: show resolved coordinates and node ids
    if os.environ.get("DEBUG_ROUTING", "").strip():
        print(f"[DEBUG] origin='{origin}' -> lat={src_geo['lat']}, lon={src_geo['lon']}, node={src_node}")
        print(f"[DEBUG] dest='{dest}' -> lat={dst_geo['lat']}, lon={dst_geo['lon']}, node={dst_node}")
    start_trips = explore_trips(src_node)
    goal_trips = explore_trips(dst_node)
    journeys = find_journeys(start_trips, goal_trips)
    best = filter_best_journeys(journeys, max_results=5)

    # Persist journeys to JSON for later querying
    try:
        out_dir = Path("output"); out_dir.mkdir(parents=True, exist_ok=True)
        payload = {
            "origin": origin,
            "destination": dest,
            "origin_geo": src_geo,
            "destination_geo": dst_geo,
            "start_node": src_node,
            "dest_node": dst_node,
            "journeys": [
                {
                    "path": j["path"],
                    "decoded_path": [decode_trip(t) for t in j["path"]],
                    "costs": j["costs"],
                    "transfers": max(0, len(j["path"]) - 1)
                } for j in best
            ]
        }
        with open(out_dir / "journeys.json", "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

    formatted = format_journeys_for_user(best)

    # 3) Single LLM call for final Arabic answer, prefer 2.5-flash then fallback to pro
    polish_prompt = (
        f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±ÙŠØ¯ Ø§Ù„Ø°Ù‡Ø§Ø¨ Ù…Ù† {origin} Ø¥Ù„Ù‰ {dest}.\n\n" 
        "Ø£ÙƒØ¯ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù‚ØªØ±Ø­ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ ÙˆÙ…ÙÙ‡ÙˆÙ…ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ù„Ù‡Ø¬ØªÙ‡ Ø§Ù„Ù…ØµØ±ÙŠØ© Ø¥Ù† Ø£Ù…ÙƒÙ†ØŒ"
        " Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙˆØ§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØ§Ù„Ø£Ø³Ù…Ø§Ø¡ ÙƒÙ…Ø§ Ù‡ÙŠ ØªÙ…Ø§Ù…Ù‹Ø§.\n\n" + formatted
    )
    try:
        resp = genai.GenerativeModel("gemini-2.5-flash").generate_content(polish_prompt, request_options={"retry": None, "timeout": 60})
        return getattr(resp, "text", str(resp))
    except Exception:
        try:
            resp = genai.GenerativeModel("gemini-2.5-flash").generate_content(polish_prompt, request_options={"retry": None, "timeout": 60})
            return getattr(resp, "text", str(resp))
        except Exception:
            return formatted


def query_saved_journeys() -> dict | None:
    """Load last saved journeys from output/journeys.json."""
    p = Path("output/journeys.json")
    if not p.exists():
        return None
    try:
        with open(p, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

if __name__ == "__main__":
    user_query = "Ø£Ø±ÙŠØ¯ Ø§Ù„Ø°Ù‡Ø§Ø¨ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø§Ù„ÙŠ Ø§Ù„Ø¹ØµØ§ÙØ±Ø©"
    print(" Ø§Ù„Ø³Ø¤Ø§Ù„:", user_query)
    out = run_once(user_query)
    print(" Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
    print(out)
    saved = query_saved_journeys()
    if saved:
        print("\n[Saved] output/journeys.json written with current results.")
# agent.run("Ø£Ø±ÙŠØ¯ Ø§Ù„Ø°Ù‡Ø§Ø¨ Ù…Ù† Ø§Ù„Ø¹Ø¬Ù…ÙŠ Ø¥Ù„Ù‰ Ù…Ø­Ø·Ø© Ø§Ù„Ø±Ù…Ù„")

# response = model.invoke("Ù‡Ùˆ Ø§Ø²Ø§ÙŠ Ø§Ø±ÙˆØ­ Ù…Ù† Ù…Ø­Ø·Ø© Ù…ØµØ± Ù„Ù„Ø¹Ø¬Ù…ÙŠ ØŸ ÙÙŠ Ù…Ø´Ø§Ø±ÙŠØ¹ Ø¨ØªØ±ÙˆØ­ Ù‡Ù†Ø§ÙƒØŸ")
# print(response.content)