from langchain.tools import tool
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
import os
load_dotenv()
from langchain_google_genai import ChatGoogleGenerativeAI
from tools import geocode_address, find_route_server, format_server_journeys_for_user
from langchain.agents import create_agent
from services.geocode import geocode_address as svc_geocode
from services.routing_client import find_route as svc_find_route
from trip_decoder import decode_trip
import re, json
import google.generativeai as genai

system_prompt = """
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ù…ÙˆØ§ØµÙ„Ø§Øª Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©.
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø¯Ù‚Ø©:

1. geocode_address(address): Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª.
2. find_route_server(start_address, end_address, walking_cutoff=1000, max_transfers=2): Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø®Ø§Ø¯Ù… gRPC ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø±Ø­Ù„Ø§Øª.
3. format_server_journeys_for_user(route_response): Ù„ØµÙŠØ§ØºØ© Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ø´ÙƒÙ„ Ø¹Ø±Ø¨ÙŠ ÙˆÙˆØ¯ÙˆØ¯.

Ø§Ù„ØªØ¯ÙÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
- ÙÙ‡Ù… Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù†Ù‚Ø·Ø© Ø¨Ø¯Ø§ÙŠØ© ÙˆÙ†Ù‡Ø§ÙŠØ©).
- Geocode Ù„Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†.
- Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø³ÙŠØ±ÙØ± (FindRoute) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±.
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØµÙŠØ§ØºØ© Ø±Ø¯ Ù†Ù‡Ø§Ø¦ÙŠ ÙˆØ§Ø¶Ø­ ÙˆÙ„Ø·ÙŠÙ ÙŠØµÙ„Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠ.
Ø£Ø¹Ø¯ ÙÙ‚Ø· Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù….
"""

model = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, google_api_key=os.getenv("GOOGLE_API_KEY"))

tools = [geocode_address, find_route_server, format_server_journeys_for_user]

agent = create_agent(model, tools=tools)

def _llm_parse_places(query: str) -> tuple[str | None, str | None]:
    """Parse origin/destination via Google Generative AI directly (JSON-only)."""
    try:
        api_key = os.environ.get("GOOGLE_API_KEY", "").strip()
        if not api_key:
            return None, None
        genai.configure(api_key=api_key)
        parse_prompt = (
            "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù†ÙˆØ§ÙŠØ§. Ø£Ø®Ø±Ø¬ Ù…ÙƒØ§Ù† Ø§Ù„Ø§Ù†Ø·Ù„Ø§Ù‚ ÙˆØ§Ù„ÙˆØµÙˆÙ„ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ£Ø¹Ø¯ JSON ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ ÙƒÙ„Ø§Ù… Ø¥Ø¶Ø§ÙÙŠØŒ"
            " Ø§Ø³ØªØ¹Ù…Ù„ Ø§Ù„Ù…ÙØªØ§Ø­ÙŠÙ† Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ØªÙ…Ø§Ù…Ù‹Ø§: origin Ùˆ destination. Ø£Ø¹ÙØ¯Ù‘ JSON Ù…Ø¶ØºÙˆØ· Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ø¨Ø¯ÙˆÙ† Ø£Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯Ø© ÙˆÙ„Ø§ ØªØ¹Ù„ÙŠÙ‚Ø§Øª"
            " ÙˆØ¨Ø¯ÙˆÙ† Ø£Ù‚ÙˆØ§Ø³ Ø£Ùˆ ØªÙ†Ø³ÙŠÙ‚ Ø¥Ø¶Ø§ÙÙŠ Ù…Ø«Ù„ ``` Ø£Ùˆ ```json. Ù…Ø«Ø§Ù„ Ø¯Ù‚ÙŠÙ‚: {\"origin\":\"Ø§Ù„Ù…ÙˆÙ‚Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯\",\"destination\":\"Ø§Ù„Ø¹ØµØ§ÙØ±Ø©\"}.\n\n"
            f"Ø§Ù„Ù†Øµ: {query}"
        )
        resp = genai.GenerativeModel("gemini-2.5-flash").generate_content(parse_prompt, request_options={"retry": None, "timeout": 20})
        raw = getattr(resp, "text", "") or ""
        raw = re.sub(r"^```[a-zA-Z]*\n|\n```$", "", raw.strip())
        raw = raw.strip()
        m = re.search(r"\{[\s\S]*\}", raw)
        if not m:
            return None, None
        data = json.loads(m.group(0))
        origin = (data.get("origin") or data.get("Ø§Ù„Ø§Ù†Ø·Ù„Ø§Ù‚") or "").strip() or None
        dest = (data.get("destination") or data.get("Ø§Ù„ÙˆØµÙˆÙ„") or "").strip() or None
        return origin, dest
    except Exception:
        return None, None


def run_once_server(query: str) -> str:
    """LLM-only parse, call gRPC server, format Arabic reply."""
    origin, dest = _llm_parse_places(query)
    if not origin or not dest:
        return (
            "ØªØ¹Ø°Ù‘Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ø§Ù†Ø·Ù„Ø§Ù‚ ÙˆØ§Ù„ÙˆØµÙˆÙ„ Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø¨Ø±Ø¬Ø§Ø¡ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø¨ÙˆØ¶ÙˆØ­ Ù…Ø«Ù„Ø§Ù‹: "
            "'Ø£Ø±ÙŠØ¯ Ø§Ù„Ø°Ù‡Ø§Ø¨ Ù…Ù† [Ø§Ù„Ù…ÙƒØ§Ù†] Ø¥Ù„Ù‰ [Ø§Ù„Ù…ÙƒØ§Ù†]'."
        )

    s = svc_geocode(origin)
    e = svc_geocode(dest)
    if "error" in s or "error" in e:
        return (
            "ØªØ¹Ø°Ù‘Ø± ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹. Ø¬Ø±Ù‘Ø¨ Ø£Ø³Ù…Ø§Ø¡ Ø¨Ø¯ÙŠÙ„Ø© Ø£Ùˆ ØµÙŠØºØ© Ø£Ø¯Ù‚.\n"
            f"Start: {origin} => {s}\nEnd  : {dest} => {e}"
        )

    resp = svc_find_route(
        start_lat=s["lat"], start_lon=s["lon"], end_lat=e["lat"], end_lon=e["lon"],
        walking_cutoff=5000.0, max_transfers=2,
    )
    
    # Inline formatting logic (instead of calling tool-wrapped function)
    formatted = _format_journeys(resp, origin, dest)

    # Try a final polish via LLM; fallback to raw formatted text
    try:
        polish = (
            f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±ÙŠØ¯ Ø§Ù„Ø°Ù‡Ø§Ø¨ Ù…Ù† {origin} Ø¥Ù„Ù‰ {dest}.\n\n"
            "Ù…Ù† ÙØ¶Ù„Ùƒ Ù‚Ø¯Ù… Ù†ÙØ³ Ø§Ù„Ø±Ø­Ù„Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø´ÙƒÙ„ ÙˆØ¯ÙˆØ¯ ÙˆÙˆØ§Ø¶Ø­ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©ØŒ"
            " Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø£Ùˆ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø£Ùˆ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø®Ø·ÙˆØ·:\n\n" + formatted
        )
        r = model.invoke(polish)
        return getattr(r, "content", str(r))
    except Exception:
        return formatted


def _format_journeys(route_response: dict, origin: str, dest: str) -> str:
    """Format gRPC route response into friendly Arabic guidance."""
    if not route_response or route_response.get("num_journeys", 0) == 0:
        return "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø­Ù„Ø§Øª Ù…Ù†Ø§Ø³Ø¨Ø© Ø¨Ø§Ù„Ù‚Ø±Ø¨ Ù…Ù† Ù†Ù‚Ø·ØªÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø£Ùˆ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ø¶Ù…Ù† Ù…Ø³Ø§ÙØ© Ø§Ù„Ù…Ø´ÙŠ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©."

    journeys = route_response.get("journeys", [])

    output = f"**Ù…Ù† {origin} Ø¥Ù„Ù‰ {dest}**\n\n"
    for i, journey in enumerate(journeys, 1):
        path = journey.get("path", [])
        costs = journey.get("costs", {})

        readable_path = [decode_trip(t) for t in path]
        path_text = " â†’ ".join(readable_path) if readable_path else "(Ù…Ø³Ø§Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ)"

        money = costs.get("money", 0)
        walk_m = int(costs.get("walk", 0))
        time_min = int(costs.get("transport_time", 0))

        output += f"""
ğŸ”¹ Ø§Ù„Ø±Ø­Ù„Ø© {i}:
ğŸ›£ Ø§Ù„Ù…Ø³Ø§Ø±: {path_text}
ğŸ’° Ø§Ù„Ø³Ø¹Ø± Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ: {money} Ø¬Ù†ÙŠÙ‡
ğŸš¶â€â™‚ï¸ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø´ÙŠ: {walk_m} Ù…ØªØ±
â± Ø²Ù…Ù† Ø§Ù„ØªÙ†Ù‚Ù„: ~{time_min} Ø¯Ù‚ÙŠÙ‚Ø©

"""

    output += "\nÙ†ØµÙŠØ­Ø©: Ø§ØªØ¨Ø¹ Ù‡Ø°Ø§ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ù…Ù† Ø§Ù„Ø±Ø­Ù„Ø§ØªØŒ ÙˆØ¥Ø°Ø§ Ø§Ø­ØªØ¬Øª Ù…Ø³Ø§Ø¹Ø¯Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ø³Ù… Ø§Ù„Ø®Ø· Ø§Ù„Ù…Ø°ÙƒÙˆØ± Ø¨ÙŠÙ† Ø§Ù„Ù‚ÙˆØ³ÙŠÙ† Ù„ÙƒÙ„ Ù…Ø±Ø­Ù„Ø©.\nÙ†ØªÙ…Ù†Ù‰ Ù„Ùƒ Ø±Ø­Ù„Ø© Ù…ÙˆÙÙ‚Ø©!"
    return output

# Add timeout to prevent hanging
import signal

def timeout_handler(signum, frame):
    raise TimeoutError("Agent call timed out after 60 seconds")

# Note: signal.alarm only works on Unix. For Windows, we'll catch KeyboardInterrupt
try:
    user_query = os.getenv("TEST_QUERY", "Ø£Ø±ÙŠØ¯ Ø§Ù„Ø°Ù‡Ø§Ø¨ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ Ø§Ù„Ø¹ØµØ§ÙØ±Ø©")
    print("Starting agent... (Press Ctrl+C if it hangs)")
    # Prefer deterministic server path to avoid model quotas
    output = run_once_server(user_query)
    print("\n" + "="*60)
    print("Agent Response:")
    print("="*60)
    print(output)
except KeyboardInterrupt:
    print("\n\nInterrupted by user. Try running test_direct_call.py instead.")
except Exception as e:
    print(f"\nError: {e}")
    import traceback
    traceback.print_exc()
    print("\nTry running: python test_direct_call.py")

# response = model.invoke("Ù‡Ùˆ Ø§Ø²Ø§ÙŠ Ø§Ø±ÙˆØ­ Ù…Ù† Ù…Ø­Ø·Ø© Ù…ØµØ± Ù„Ù„Ø¹Ø¬Ù…ÙŠ ØŸ ÙÙŠ Ù…Ø´Ø§Ø±ÙŠØ¹ Ø¨ØªØ±ÙˆØ­ Ù‡Ù†Ø§ÙƒØŸ")
# print(response.content)